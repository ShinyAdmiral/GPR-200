// GLSL STARTER CODE BY DANIEL S. BUCKSTEIN
//  -> COMMON TAB (shared with all other tabs)

//------------------------------------------------------------
// TYPE ALIASES & UTILITY FUNCTIONS

// sScalar: alias for a 1D scalar (non-vector)
#define sScalar float

// sCoord: alias for a 2D coordinate
#define sCoord vec2

// sDCoord: alias for a 2D displacement or measurement
#define sDCoord vec2

// sBasis: alias for a 3D basis vector
#define sBasis vec3

// sPoint: alias for a point/coordinate/location in space
#define sPoint vec4

// sVector: alias for a vector/displacement/change in space
#define sVector vec4

//definition of pi
#define pi 3.1415926535897932384626

// color3: alias for a 3D vector representing RGB color
// 	(this is non-spatial so neither a point nor vector)
#define color3 vec3

// color4: alias for RGBA color, which is non-spatial
// 	(this is non-spatial so neither a point nor vector)
#define color4 vec4

// asPoint: promote a 3D vector into a 4D vector 
//	representing a point in space (w=1)
//    v: input 3D vector to be converted
sPoint asPoint(in sBasis v)
{
    return sPoint(v, 1.0);
}

// asVector: promote a 3D vector into a 4D vector 
//	representing a vector through space (w=0)
//    v: input 3D vector to be converted
sVector asVector(in sBasis v)
{
    return sVector(v, 0.0);
}


// lengthSq: calculate the squared length of a vector type
//    x: input whose squared length to calculate
sScalar lengthSq(sScalar x)
{
    return (x * x);
    //return dot(x, x); // for consistency with others
}
sScalar lengthSq(sDCoord x)
{
    return dot(x, x);
}
sScalar lengthSq(sBasis x)
{
    return dot(x, x);
}
sScalar lengthSq(sVector x)
{
    return dot(x, x);
}

//----------------------------
//define matrix 5 (Not Used)
//----------------------------

//struct mat5{
//	float a[5];
//    float b[5];
//    float c[5];
//    float d[5];
//    float e[5];
//};

//------------------------------------------------------------
// VIEWPORT INFO

// sViewport: info about viewport
//    viewportPoint: location on the viewing plane 
//							x = horizontal position
//							y = vertical position
//							z = plane depth (negative focal length)
//	  pixelCoord:    position of pixel in image
//							x = [0, width)	-> [left, right)
//							y = [0, height)	-> [bottom, top)
//	  resolution:    resolution of viewport
//							x = image width in pixels
//							y = image height in pixels
//    resolutionInv: resolution reciprocal
//							x = reciprocal of image width
//							y = reciprocal of image height
//	  size:       	 in-scene dimensions of viewport
//							x = viewport width in scene units
//							y = viewport height in scene units
//	  ndc: 			 normalized device coordinate
//							x = [-1, +1) -> [left, right)
//							y = [-1, +1) -> [bottom, top)
// 	  uv: 			 screen-space (UV) coordinate
//							x = [0, 1) -> [left, right)
//							y = [0, 1) -> [bottom, top)
//	  aspectRatio:   aspect ratio of viewport
//	  focalLength:   distance to viewing plane
struct sViewport
{
    sPoint viewportPoint;
	sCoord pixelCoord;
	sDCoord resolution;
	sDCoord resolutionInv;
	sDCoord size;
	sCoord ndc;
	sCoord uv;
	sScalar aspectRatio;
	sScalar focalLength;
};

// initViewport: calculate the viewing plane (viewport) coordinate
//    vp: 		      output viewport info structure
//    viewportHeight: input height of viewing plane
//    focalLength:    input distance between viewer and viewing plane
//    fragCoord:      input coordinate of current fragment (in pixels)
//    resolution:     input resolution of screen (in pixels)
void initViewport(out sViewport vp,
                  in sScalar viewportHeight, in sScalar focalLength,
                  in sCoord fragCoord, in sDCoord resolution)
{
    vp.pixelCoord = fragCoord;
    vp.resolution = resolution;
    vp.resolutionInv = 1.0 / vp.resolution;
    vp.aspectRatio = vp.resolution.x * vp.resolutionInv.y;
    vp.focalLength = focalLength;
    vp.uv = vp.pixelCoord * vp.resolutionInv;
    vp.ndc = vp.uv * 2.0 - 1.0;
    vp.size = sDCoord(vp.aspectRatio, 1.0) * viewportHeight;
    vp.viewportPoint = asPoint(sBasis(vp.ndc * vp.size * 0.5, -vp.focalLength));
}


//------------------------------------------------------------
// RAY INFO

// sRay: ray data structure
//	  origin: origin point in scene
//    direction: direction vector in scene
struct sRay
{
    sPoint origin;
    sVector direction;
};

// initRayPersp: initialize perspective ray
//    ray: 		   output ray
//    eyePosition: position of viewer in scene
//    viewport:    input viewing plane offset
void initRayPersp(out sRay ray,
             	  in sBasis eyePosition, in sBasis viewport)
{
    // ray origin relative to viewer is the origin
    // w = 1 because it represents a point; can ignore when using
    ray.origin = asPoint(eyePosition);

    // ray direction relative to origin is based on viewing plane coordinate
    // w = 0 because it represents a direction; can ignore when using
    ray.direction = asVector(viewport - eyePosition);
}

// initRayOrtho: initialize orthographic ray
//    ray: 		   output ray
//    eyePosition: position of viewer in scene
//    viewport:    input viewing plane offset
void initRayOrtho(out sRay ray,
             	  in sBasis eyePosition, in sBasis viewport)
{
    // offset eye position to point on plane at the same depth
    initRayPersp(ray, eyePosition + sBasis(viewport.xy, 0.0), viewport);
}

//Rotate Cube
vec3 rotateCubeY(sRay ray, float rad){
    //grab trig of time
    float cosNum = cos(rad);
    float sinNum = sin(rad);
    
    //get rotation matrix of y coord with tim
    mat3 rm = mat3(  cosNum, 0.0,   -sinNum,
            	        0.0, 1.0,       0.0, 
                     sinNum, 0.0,    cosNum);
    
    //return rotation
   	return ray.direction.xyz * rm;
}

//Rotate Cube
vec3 rotateCubeY(sRay ray, vec2 rad){
    //grab trig of mouse input y
    float cosNumY = cos(rad.y + pi);
    float sinNumY = sin(rad.y + pi);
    
    //grab trig of mouse input x
    float cosNumX = cos(-rad.x + pi);
    float sinNumX = sin(-rad.x + pi);
    
    //get roptation matrix
    mat3 rm = mat3(   cosNumX, sinNumX * sinNumY,    sinNumX * cosNumY,
            	         	0, 	         cosNumY,         	  -sinNumY, 
                     -sinNumX, cosNumX * sinNumY,    cosNumY * cosNumX);
    
    
    //return rotation
   	return ray.direction.xyz * rm;
}

//Luminosity
//Credit: https://en.wikipedia.org/wiki/Relative_luminance
float getLum(in color4 color)
{
    //return luiminosity
    return 0.2126 * color.x + 0.7152 * color.y + 0.0722 * color.z;
}

vec4 guassianBlur(sampler2D tex, vec2 coord, vec2 res){
    //make temp color
	vec4 color = vec4(0.0);
    
    //add each sample to the final color after calculating color, 
    //weight, and resolution of each pixel at the coord
    
    //Please not that the gaussian weights have been averaged because
    //samples are being taken from the corners of the sample blocks
    color += texture(tex, (coord + vec2(-1.5,  -1.5)) * res) * 6.25;
    color += texture(tex, (coord + vec2(-1.5,  -0.5)) * res) * 12.5;
    color += texture(tex, (coord + vec2(-1.5,   0.5)) * res) * 12.5;
    color += texture(tex, (coord + vec2(-1.5,   1.5)) * res) * 22.0;
    
    color += texture(tex, (coord + vec2(-0.5,  -1.5)) * res) * 12.5;
    color += texture(tex, (coord + vec2(-0.5,  -0.5)) * res) * 25.0;
    color += texture(tex, (coord + vec2(-0.5,   0.5)) * res) * 25.0;
    color += texture(tex, (coord + vec2(-0.5,   1.5)) * res) * 12.5;
    
    color += texture(tex, (coord + vec2( 0.5,  -1.5)) * res) * 12.5;
    color += texture(tex, (coord + vec2( 0.5,  -0.5)) * res) * 25.0;
    color += texture(tex, (coord + vec2( 0.5,   0.5)) * res) * 25.0;
    color += texture(tex, (coord + vec2( 0.5,   1.5)) * res) * 12.5;
    
    color += texture(tex, (coord + vec2( 1.5,  -1.5)) * res) * 6.25;
    color += texture(tex, (coord + vec2( 1.5,  -0.5)) * res) * 12.5;
    color += texture(tex, (coord + vec2( 1.5,   0.5)) * res) * 12.5;
    color += texture(tex, (coord + vec2( 1.5,   1.5)) * res) * 6.25;
    
    //return color after weight inverse is multiplied
	return color * 0.00390625;
}

vec4 edgeDetection(sampler2D tex, vec2 coord, vec2 res){
    //make temp color
	vec4 color = vec4(0.0);
    
    //add each sample to the final color after calculating color, 
    //weight, and resolution of each pixel at the coord
    color += texture(tex, (coord + vec2(-1.0,  -1.0)) * res) * -1.0;
    color += texture(tex, (coord + vec2(-1.0,   0.0)) * res) * -1.0;
    color += texture(tex, (coord + vec2(-1.0,   1.0)) * res) * -1.0;
    
    color += texture(tex, (coord + vec2( 0.0,  -1.0)) * res) * -1.0;
    color += texture(tex, (coord + vec2( 0.0,   0.0)) * res) *  8.0;
    color += texture(tex, (coord + vec2( 0.0,   1.0)) * res) * -1.0;
    
    color += texture(tex, (coord + vec2( 1.0,  -1.0)) * res) * -1.0;
    color += texture(tex, (coord + vec2( 1.0,   0.0)) * res) * -1.0;
    color += texture(tex, (coord + vec2( 1.0,   1.0)) * res) * -1.0;
    
    //return color. No inverse weight since -8 and 8 make 0
	return color;
}

vec4 add(sampler2D tex1, sampler2D tex2, vec2 uv)
{
    //start with empty color
	vec4 color = vec4(0.0);
    
    //add both colors
    color += texture(tex1, uv);
    color += texture(tex2, uv);
    
    //return color
    return color;
}



//Implements the screen convolution algorithm
//Inverts the indiviual textures, multiplies those and then inverts the result.
vec4 screen(sampler2D tex1, sampler2D tex2, vec2 uv)
{
    
    vec4 c1 = texture(tex1, uv);
    vec4 c2 = texture(tex2, uv);
    c1 = vec4(1. - c1.x, 1. - c1.y, 1. - c1.z, 1. - c1.w);
    c2 = vec4(1. - c2.x, 1. - c2.y, 1. - c2.z, 1. - c2.w);
    c1 *= c2;
    return vec4(1. - c1.x, 1. - c1.y, 1. - c1.z, 1. - c1.w);
}

//Multiply convolution algorithm 
//Multiplies the two inputed textures together.
vec4 multiply(sampler2D tex1, sampler2D tex2, vec2 uv)
{
    return texture(tex1, uv) * texture(tex2, uv);
}

// --------------------------------------------------------------------
// Used for the Old Gaussian Blur
// --------------------------------------------------------------------

//vec4 guassianBlur(sampler2D tex, vec2 coord, vec2 res, mat5 kernel){
//	vec4 color = vec4(0.0);
//    
//    color += texture(tex, (coord + vec2(-2.0,  2.0)) * res) * kernel.a[0];
//    color += texture(tex, (coord + vec2(-2.0,  1.0)) * res) * kernel.a[1];
//    color += texture(tex, (coord + vec2(-2.0,  0.0)) * res) * kernel.a[2];
//    color += texture(tex, (coord + vec2(-2.0, -1.0)) * res) * kernel.a[3];
//    color += texture(tex, (coord + vec2(-2.0, -2.0)) * res) * kernel.a[4];
//    
//    color += texture(tex, (coord + vec2(-1.0,  2.0)) * res) * kernel.b[0];
//    color += texture(tex, (coord + vec2(-1.0,  1.0)) * res) * kernel.b[1];
//    color += texture(tex, (coord + vec2(-1.0,  0.0)) * res) * kernel.b[2];
//    color += texture(tex, (coord + vec2(-1.0, -1.0)) * res) * kernel.b[3];
//    color += texture(tex, (coord + vec2(-1.0, -2.0)) * res) * kernel.b[4];
//    
//    color += texture(tex, (coord + vec2( 0.0,  2.0)) * res) * kernel.c[0];
//    color += texture(tex, (coord + vec2( 0.0,  1.0)) * res) * kernel.c[1];
//    color += texture(tex, (coord + vec2( 0.0,  0.0)) * res) * kernel.c[2];
//    color += texture(tex, (coord + vec2( 0.0, -1.0)) * res) * kernel.c[3];
//    color += texture(tex, (coord + vec2( 0.0, -2.0)) * res) * kernel.c[4];
//    
//    color += texture(tex, (coord + vec2( 1.0,  2.0)) * res) * kernel.b[0];
//    color += texture(tex, (coord + vec2( 1.0,  1.0)) * res) * kernel.b[1];
//    color += texture(tex, (coord + vec2( 1.0,  0.0)) * res) * kernel.b[2];
//    color += texture(tex, (coord + vec2( 1.0, -1.0)) * res) * kernel.b[3];
//    color += texture(tex, (coord + vec2( 1.0, -2.0)) * res) * kernel.b[4];
//    
//    color += texture(tex, (coord + vec2( 2.0,  2.0)) * res) * kernel.a[0];
//    color += texture(tex, (coord + vec2( 2.0,  1.0)) * res) * kernel.a[1];
//    color += texture(tex, (coord + vec2( 2.0,  0.0)) * res) * kernel.a[2];
//    color += texture(tex, (coord + vec2( 2.0, -1.0)) * res) * kernel.a[3];
//    color += texture(tex, (coord + vec2( 2.0, -2.0)) * res) * kernel.a[4];
//    
//	return color * 1./256.;
//}

//------------------------------------------------------------
/*
// GLSL FRAGMENT SHADER STRUCTURE WITH COMMON TAB
//  -> This is (likely) how Shadertoy compiles buffer tabs:

// latest version or whichever is used
#version 300 es

// **CONTENTS OF COMMON TAB PASTED HERE**

// PROGRAM UNIFORMS (see 'Shader Inputs' dropdown)

// **CONTENTS OF BUFFER TAB PASTED HERE**

// FRAGMENT SHADER INPUTS (more on this later)

// FRAGMENT SHADER OUTPUTS (framebuffer render target(s))
//out vec4 rtFragColor; // no specific target
layout (location = 0) out vec4 rtFragColor; // default

void main()
{
    // Call 'mainImage' in actual shader main, which is 
	// 	our prototyping interface for ease of use.
	//		rtFragColor:  shader output passed by reference,
	//			full vec4 read in 'mainImage' as 'fragColor'
	//		gl_FragCoord: GLSL's built-in pixel coordinate,
	//			vec2 part read in 'mainImage' as 'fragCoord'
    mainImage(rtFragColor, gl_FragCoord.xy);
}
*/